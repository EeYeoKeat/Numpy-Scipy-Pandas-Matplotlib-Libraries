{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Surprise load own dataset - Practice 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTF7BTiA6sew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "7b41cc4f-ef1e-40de-976e-4c3c83c81853"
      },
      "source": [
        "# Install surprise in Colab\n",
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.17.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1678061 sha256=37155a4fdef65bf0c66d7a8dfe65e26455ff1fb27443d3a1d84ed10482150e34\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.0 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMbOg0xy6_6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3be0f0da-b864-44f1-fdc2-496ecfe133cc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from surprise import NormalPredictor\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "\n",
        "# Creation of the dataframe. Column names are irrelevant.\n",
        "ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
        "                'userID': [9, 32, 2, 45, 'user_foo'],\n",
        "                'rating': [3, 2, 4, 3, 1]}\n",
        "df = pd.DataFrame(ratings_dict)\n",
        "\n",
        "# A reader is still needed but only the rating_scale param is requiered.\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# The columns must correspond to user id, item id and ratings (in that order).\n",
        "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
        "\n",
        "# We can now use this dataset as we please, e.g. calling cross_validate\n",
        "cross_validate(NormalPredictor(), data, cv=5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (8.797645568847656e-05,\n",
              "  5.364418029785156e-05,\n",
              "  7.62939453125e-05,\n",
              "  4.9114227294921875e-05,\n",
              "  4.9591064453125e-05),\n",
              " 'test_mae': array([1.94158047, 2.75671813, 0.86021779, 1.80198524, 0.09521444]),\n",
              " 'test_rmse': array([1.94158047, 2.75671813, 0.86021779, 1.80198524, 0.09521444]),\n",
              " 'test_time': (3.9577484130859375e-05,\n",
              "  2.47955322265625e-05,\n",
              "  2.3603439331054688e-05,\n",
              "  2.2411346435546875e-05,\n",
              "  2.1457672119140625e-05)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vJTGF6GBlNo",
        "colab_type": "text"
      },
      "source": [
        "# Use cross-validation iterators\n",
        "\n",
        "For cross-validation, we can use the cross_validate() function that does all the hard work for us. But for a better control, we can also instanciate a cross-validation iterator, and make predictions over each split using the split() method of the iterator, and the test() method of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5c2wwII-_8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6bf353a0-fc1d-4ac8-b4a1-118189742941"
      },
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold\n",
        "\n",
        "# Load the movielens-100k dataset\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# define a cross-validation iterator\n",
        "kf = KFold(n_splits=3)\n",
        "\n",
        "algo = SVD()\n",
        "\n",
        "for trainset, testset in kf.split(data):\n",
        "\n",
        "    # train and test algorithm.\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "\n",
        "    # Compute and print Root Mean Squared Error\n",
        "    accuracy.rmse(predictions, verbose=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "RMSE: 0.9388\n",
            "RMSE: 0.9445\n",
            "RMSE: 0.9514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkM2UmTLCBbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}